---
title: "Predicting Breast Cancer dashboard"
output: 
  flexdashboard::flex_dashboard:
  orientation: columns
---

```{r setup, include=FALSE}
library(flexdashboard)
```

Column {data-width = 300}
-----------------------------------------------------------------------

### women will develop breast cancer in her lifetime [(source)](http://www.breastcancer.org/symptoms/understand_bc/statistics)

```{r}
valueBox("1 in 8", icon = "fa-female", color = "rgb(201, 199, 197)")
```

### of breast cancers occur in women with no family history of breast cancer [(source)](http://www.breastcancer.org/symptoms/understand_bc/statistics)

```{r}
valueBox("85%", icon = "fa-female", color = "rgb(201, 199, 197)")
```

### Measuring breast masses for cancer diagnosis 

Biopsy via fine-needle aspiration is a relatively non-invasive and quick technique for assessing the malignancy of breast lumps ([source](https://bmccancer.biomedcentral.com/articles/10.1186/1471-2407-12-41)). Breast lump biopsies are sent to pathologists who then examine the tissue sample to assess whether the cells are cancerous or not. Machine learning applications could help improve and streamline this process by extracting tissue characteristics (mean area, symmetry, concavity, etc.) from microscope images and then feeding this information into the stacked machine learning model to predict the tissue's malignancy (with 97.7% accuracy). 

Early detection is key to recovery from breast cancer. Women who are diagnosed at the earliest stage of breast cancer have a much greater chance of surviving (> 90%) compared to women who are diagnosed at the most advanced stage (only 5%, [source](http://www.cancerresearchuk.org/about-cancer/cancer-symptoms/why-is-early-diagnosis-important)). Leveraging data and machine learning approaches could help to speed up breast cancer diagnosis and detection.

The scatterplot to the left illustrates the key differences between malignant (gray) and benign (red) breast tumors. Each point represents a breast tumor based on the characteristics of it's cell nuclei. Points that are closer together are tumors that have more similar cell nuclei, while points farther away from each other are tumors with more dissimilar cell nuclei. Each line is a vector representing a particular characteristic of the cell nuclei. Values of that characteristic increase along the vector (starting from the origin, 0,0), so for instance malignant tumors have larger values for the nuclei's mean area, standard error of the radius, and standard error of nuclei concavity compared to benign tumors. Similarly, benign tumors tend to have larger standard errors of the nuclei symmetry compared to malignant tumors.

Column {data-width = 700}
-----------------------------------------------------------------------

### Characteristics of breast cancer masses

```{r}
# PCA
library(readr)
library(tidyverse)
library(plotly)

data <- read_csv("~/Documents/Data Science/GitHub_repository/MachineLearningPortfolio/PredictingBreastCancer/data.csv")
library(tsne)
set.seed(7)
sne <- tsne(data[ , 3:10])
snne <- as.data.frame(sne)

library(vegan)
set.seed(7)
fit <- envfit(snne ~ data$area_mean + data$radius_se + data$texture_worst + data$smoothness_worst + data$symmetry_worst + 
                data$concavity_se + data$fractal_dimension_worst + data$symmetry_se)
vectors <- as.data.frame(fit$vectors$arrows)
vectors <- vectors*40

origin <- as.data.frame(matrix(0, ncol = 2, nrow = 1))

data_1 <- rbind(origin, vectors[1, ])
data_2 <- rbind(origin, vectors[2, ])
data_3 <- rbind(origin, vectors[3, ])
data_4 <- rbind(origin, vectors[4, ])
data_5 <- rbind(origin, vectors[5, ])
data_6 <- rbind(origin, vectors[6, ])
data_7 <- rbind(origin, vectors[7, ])
data_8 <- rbind(origin, vectors[8, ])

plot(snne)
plot(fit)

data$diagnosis <- as.factor(data$diagnosis)
levels(data$diagnosis) <- c("Benign", "Malignant")

plot_ly() %>% 
  add_trace(data = snne, x = snne$V1, y = snne$V2, type="scatter", mode="markers", opacity = 0.7, color = ~data$diagnosis, colors = "Set1") %>% 
  add_trace(data = data_1, x = data_1$V1, y = data_1$V2, type="scatter", mode = "lines", name = "mean area", colors = "Set1") %>%
  add_trace(data = data_2, x = data_2$V1, y = data_2$V2, type="scatter", mode = "lines", name = "radius (SE)", colors = "Set1") %>%
  add_trace(data = data_3, x = data_3$V1, y = data_3$V2, type="scatter", mode = "lines", name = "texture (worst)", colors = "Set1") %>%
  add_trace(data = data_4, x = data_4$V1, y = data_4$V2, type="scatter", mode = "lines", name = "smoothness (worst)", colors = "Set1") %>%
  add_trace(data = data_5, x = data_5$V1, y = data_5$V2, type="scatter", mode = "lines", name = "symmetry (worst)", colors = "Set1") %>%
  add_trace(data = data_6, x = data_6$V1, y = data_6$V2, type="scatter", mode = "lines", name = "cell concavity (SE)", colors = "Set1") %>%
  add_trace(data = data_7, x = data_7$V1, y = data_7$V2, type="scatter", mode = "lines", name = "fractal dimension (worst)", colors = "Set1") %>%
  add_trace(data = data_8, x = data_8$V1, y = data_8$V2, type="scatter", mode = "lines", name = "symmetry (SE)", colors = "Set1") 


```

